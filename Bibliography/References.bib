@misc{2024GlobalTrends,
  title = {2024 {{Global Trends}} in {{AI}}},
  journal = {WEKA},
  urldate = {2024-10-26},
  abstract = {Discover key AI trends in 2024. Explore generative AI, scaling challenges, GPU demand, and sustainable practices. Download the S\&P Global report.},
  langid = {american},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/AI5HP8ZA/2024-global-trends-in-ai.html}
}

@misc{AccelSimAccelSimFramework,
  title = {Accel-{{Sim}}: {{The Accel-Sim Framework}}},
  urldate = {2024-10-26},
  howpublished = {https://accel-sim.github.io/},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/LWSL5F2A/accel-sim.github.io.html}
}

@misc{AlgorithmFlowchartEdrawMax,
  title = {Algorithm {{Flowchart}} - {{EdrawMax}}},
  urldate = {2024-03-30},
  howpublished = {https://www.edrawmax.com/online/app.html?bY3LDoJADEW/hq3BQQGXRkJ0Y1y4J5Upr3SmZChB/t6S6M5de85tL7+GKCmWKTGHLM2PcVLJ5Zq5yJQPDBN7IB3P1HLopVMcl8RL3UGQHVr7jkzqwaG++JtRXRN7vBWaMHl2UtD0hNXEc6i3M3SjrKUiNaILgWAl67g5z88vUWl7aAO4n7PYwExbQRPY3WcihfsP},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/H9T33N3L/app.html}
}

@inproceedings{bakhodaAnalyzingCUDAWorkloads2009,
  title = {Analyzing {{CUDA}} Workloads Using a Detailed {{GPU}} Simulator},
  booktitle = {2009 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}}},
  author = {Bakhoda, Ali and Yuan, George L. and Fung, Wilson W. L. and Wong, Henry and Aamodt, Tor M.},
  year = {2009},
  month = apr,
  pages = {163--174},
  publisher = {IEEE},
  address = {Boston, MA, USA},
  doi = {10.1109/ISPASS.2009.4919648},
  urldate = {2025-01-25},
  isbn = {978-1-4244-4184-6}
}

@inproceedings{caiIslandLossLearning2018,
  title = {Island {{Loss}} for {{Learning Discriminative Features}} in {{Facial Expression Recognition}}},
  booktitle = {2018 13th {{IEEE International Conference}} on {{Automatic Face}} \& {{Gesture Recognition}} ({{FG}} 2018)},
  author = {Cai, Jie and Meng, Zibo and Khan, Ahmed Shehab and Li, Zhiyuan and O'Reilly, James and Tong, Yan},
  year = {2018},
  month = may,
  pages = {302--309},
  doi = {10.1109/FG.2018.00051},
  urldate = {2024-03-30},
  abstract = {Over the past few years, Convolutional Neural Networks (CNNs) have shown promise on facial expression recognition. However, the performance degrades dramatically under real-world settings due to variations introduced by subtle facial appearance changes, head pose variations, illumination changes, and occlusions. In this paper, a novel island loss is proposed to enhance the discriminative power of deeply learned features. Specifically, the island loss is designed to reduce the intra-class variations while enlarging the inter-class differences simultaneously. Experimental results on four benchmark expression databases have demonstrated that the CNN with the proposed island loss (IL-CNN) outperforms the baseline CNN models with either traditional softmax loss or center loss and achieves comparable or better performance compared with the state-of-the-art methods for facial expression recognition.},
  keywords = {Backpropagation,Convolutional Neural Network,Databases,Face recognition,Facial Expression Recognition,Head,Island Loss,Lighting,Propagation losses,Training},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/EDDQSYYY/Cai et al. - 2018 - Island Loss for Learning Discriminative Features i.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/G8TAWYEF/8373844.html}
}

@article{chenImageSuperresolutionReconstruction2021,
  title = {Image Super-Resolution Reconstruction Based on Feature Map Attention Mechanism},
  author = {Chen, Yuantao and Liu, Linwu and Phonevilay, Volachith and Gu, Ke and Xia, Runlong and Xie, Jingbo and Zhang, Qian and Yang, Kai},
  year = {2021},
  month = jul,
  journal = {Applied Intelligence},
  volume = {51},
  number = {7},
  pages = {4367--4380},
  issn = {1573-7497},
  doi = {10.1007/s10489-020-02116-1},
  urldate = {2024-03-30},
  abstract = {To improve the issue of low-frequency and high-frequency components from feature maps being treated equally in existing image super-resolution reconstruction methods, the paper proposed an image super-resolution reconstruction method using attention mechanism with feature map to facilitate reconstruction from original low-resolution images to multi-scale super-resolution images. The proposed model consists of a feature extraction block, an information extraction block, and a reconstruction module. Firstly, the extraction block is used to extract useful features from low-resolution images, with multiple information extraction blocks being combined with the feature map attention mechanism and passed between feature channels. Secondly, the interdependence is used to adaptively adjust the channel characteristics to restore more details. Finally, the reconstruction module reforms different scales high-resolution images. The experimental results can demonstrate that the proposed method can effectively improve not only the visual effect of images but also the results on the Set5, Set14, Urban100, and Manga109. The results can demonstrate the proposed method has structurally similarity to the image reconstruction methods. Furthermore, the evaluating indicator of Peak Signal to Noise Ratio (PSNR) and Structural Similarity Index (SSIM) has been improved to a certain degree, while the effectiveness of using feature map attention mechanism in image super-resolution reconstruction applications is useful and effective.},
  langid = {english},
  keywords = {Deep learning methods,Feature map attention mechanism,Image super-resolution reconstruction,Multi-scale low-resolution images,Multiple information extraction},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/YMGUU93X/Chen et al. - 2021 - Image super-resolution reconstruction based on fea.pdf}
}

@misc{chungJinhachungTptpusim2024,
  title = {Jinhachung/Tptpu-Sim},
  author = {Chung, Jinha},
  year = {2024},
  month = jun,
  urldate = {2024-10-26},
  abstract = {A Toy-Purpose TPU Simulator}
}

@inproceedings{dingDaViTDualAttention2022,
  title = {{{DaViT}}: {{Dual Attention Vision Transformers}}},
  shorttitle = {{{DaViT}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2022},
  author = {Ding, Mingyu and Xiao, Bin and Codella, Noel and Luo, Ping and Wang, Jingdong and Yuan, Lu},
  editor = {Avidan, Shai and Brostow, Gabriel and Ciss{\'e}, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  pages = {74--92},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-20053-3_5},
  abstract = {In this work, we introduce Dual Attention Vision Transformers ~(DaViT), a simple yet effective vision transformer architecture that is able to capture global context while maintaining computational efficiency. We propose approaching the problem from an orthogonal angle: exploiting self-attention mechanisms with both ``spatial tokens'' and ``channel tokens''. With spatial tokens, the spatial dimension defines the token scope, and the channel dimension defines the token feature dimension. With channel tokens, we have the inverse: the channel dimension defines the token scope, and the spatial dimension defines the token feature dimension. We further group tokens along the sequence direction for both spatial and channel tokens to maintain the linear complexity of the entire model. We show that these two self-attentions complement each other: (i) since each channel token contains an abstract representation of the entire image, the channel attention naturally captures global interactions and representations by taking all spatial positions into account when computing attention scores between channels; (ii) the spatial attention refines the local representations by performing fine-grained interactions across spatial locations, which in turn helps the global information modeling in channel attention. Extensive experiments show DaViT backbones achieve state-of-the-art performance on four different tasks. Specially, DaViT-Tiny, DaViT-Small, and DaViT-Base achieve 82.8\%, 84.2\%, and 84.6\% top-1 accuracy on ImageNet-1K without extra training data, using 28.3M, 49.7M, and 87.9M parameters, respectively. When we further scale up DaViT with 1.5B weakly supervised image and text pairs, DaViT-Giant reaches 90.4\% top-1 accuracy on ImageNet-1K. Code is available at https://github.com/microsoft/DaViT.},
  isbn = {978-3-031-20053-3},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/KC23TA4F/Ding et al. - 2022 - DaViT Dual Attention Vision Transformers.pdf}
}

@article{duCompoundFacialExpressions2014,
  title = {Compound Facial Expressions of Emotion},
  author = {Du, Shichuan and Tao, Yong and Martinez, Aleix M.},
  year = {2014},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {15},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1322355111},
  urldate = {2024-03-30},
  abstract = {Significance             Though people regularly recognize many distinct emotions, for the most part, research studies have been limited to six basic categories---happiness, surprise, sadness, anger, fear, and disgust; the reason for this is grounded in the assumption that only these six categories are differentially represented by our cognitive and social systems. The results reported herein propound otherwise, suggesting that a larger number of categories is used by humans.           ,              Understanding the different categories of facial expressions of emotion regularly used by us is essential to gain insights into human cognition and affect as well as for the design of computational models and perceptual interfaces. Past research on facial expressions of emotion has focused on the study of six basic categories---happiness, surprise, anger, sadness, fear, and disgust. However, many more facial expressions of emotion exist and are used regularly by humans. This paper describes an important group of expressions, which we call compound emotion categories. Compound emotions are those that can be constructed by combining basic component categories to create new ones. For instance, happily surprised and angrily surprised are two distinct compound emotion categories. The present work defines 21 distinct emotion categories. Sample images of their facial expressions were collected from 230 human subjects. A Facial Action Coding System analysis shows the production of these 21 categories is different but consistent with the subordinate categories they represent (e.g., a happily surprised expression combines muscle movements observed in happiness and surprised). We show that these differences are sufficient to distinguish between the 21 defined categories. We then use a computational model of face perception to demonstrate that most of these categories are also visually discriminable from one another.},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/WKW3B8FB/Du et al. - 2014 - Compound facial expressions of emotion.pdf}
}

@book{ekmanWhatFaceRevealsBasic2005,
  title = {What the {{Face RevealsBasic}} and {{Applied Studies}} of {{Spontaneous Expression Using}} the {{Facial Action Coding System}} ({{FACS}})},
  author = {Ekman, Paul and Rosenberg, Erika L.},
  year = {2005},
  month = apr,
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780195179644.001.0001},
  urldate = {2024-03-30},
  isbn = {978-0-19-517964-4}
}

@misc{elbtityFlexTPUFlexibleTPU2024,
  title = {Flex-{{TPU}}: {{A Flexible TPU}} with {{Runtime Reconfigurable Dataflow Architecture}}},
  shorttitle = {Flex-{{TPU}}},
  author = {Elbtity, Mohammed and Chandarana, Peyton and Zand, Ramtin},
  year = {2024},
  month = jul,
  number = {arXiv:2407.08700},
  eprint = {2407.08700},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.08700},
  urldate = {2024-12-09},
  abstract = {Tensor processing units (TPUs) are one of the most well-known machine learning (ML) accelerators utilized at large scale in data centers as well as in tiny ML applications. TPUs offer several improvements and advantages over conventional ML accelerators, like graphical processing units (GPUs), being designed specifically to perform the multiply-accumulate (MAC) operations required in the matrix-matrix and matrix-vector multiplies extensively present throughout the execution of deep neural networks (DNNs). Such improvements include maximizing data reuse and minimizing data transfer by leveraging the temporal dataflow paradigms provided by the systolic array architecture. While this design provides a significant performance benefit, the current implementations are restricted to a single dataflow consisting of either input, output, or weight stationary architectures. This can limit the achievable performance of DNN inference and reduce the utilization of compute units. Therefore, the work herein consists of developing a reconfigurable dataflow TPU, called the Flex-TPU, which can dynamically change the dataflow per layer during run-time. Our experiments thoroughly test the viability of the Flex-TPU comparing it to conventional TPU designs across multiple well-known ML workloads. The results show that our Flex-TPU design achieves a significant performance increase of up to 2.75x compared to conventional TPU, with only minor area and power overheads.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Performance},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/79GDVJ3H/Elbtity et al. - 2024 - Flex-TPU A Flexible TPU with Runtime Reconfigurable Dataflow Architecture.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/KINA5GEF/2407.html}
}

@inproceedings{farzanehDiscriminantDistributionAgnosticLoss2020,
  title = {Discriminant {{Distribution-Agnostic Loss}} for {{Facial Expression Recognition}} in the {{Wild}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  author = {Farzaneh, Amir Hossein and Qi, Xiaojun},
  year = {2020},
  pages = {406--407},
  urldate = {2024-03-30},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/KKCJKNCD/Farzaneh and Qi - 2020 - Discriminant Distribution-Agnostic Loss for Facial.pdf}
}

@misc{felkerRunningHeterogeneousCPUGPU2023,
  title = {Running a Heterogeneous {{CPU-GPU}} Simulation with {{Gem5}}},
  author = {Felker, Nick},
  year = {2023},
  month = may,
  journal = {Medium},
  urldate = {2024-10-25},
  abstract = {In my ongoing research, I have looked at the ways that non-volatile memory interacts with the CPU as a way to improve various computing{\dots}},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/SFG32QMM/running-a-heterogeneous-cpu-gpu-simulation-with-gem5-15aaa0b51f0c.html}
}

@inproceedings{gerumSourceLevelPerformance2015,
  title = {Source Level Performance Simulation of {{GPU}} Cores},
  booktitle = {2015 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
  author = {Gerum, Christoph and Bringmann, Oliver and Rosenstiel, Wolfgang},
  year = {2015},
  month = mar,
  pages = {217--222},
  issn = {1558-1101},
  doi = {10.7873/DATE.2015.0916},
  urldate = {2024-08-24},
  abstract = {Graphic processing units (GPUs) contain a lot of complex architectural features, which make performance analysis and simulation of applications using them for general purpose computation very difficult. Especially when trying to do performance simulations at a higher abstraction level than interpreted instruction set simulators these features are not handled accurately by state of the art simulation techniques. This paper proposes a method for source level performance simulation of the microarchitecture of a GPU core that provides high enough simulation speeds to make testing of large application scenarios possible.},
  keywords = {Algorithm design and analysis,Analytical models,Graphics processing units,Instruction sets,Kernel,Pipelines,Timing},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/AZZC3HGP/0916.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/5295IUHL/7092385.html}
}

@misc{GpgpusimGpgpusim_distribution2024,
  title = {Gpgpu-Sim/Gpgpu-Sim\_distribution},
  year = {2024},
  month = oct,
  urldate = {2024-10-26},
  abstract = {GPGPU-Sim provides a detailed simulation model of contemporary NVIDIA GPUs running CUDA and/or OpenCL workloads.  It includes support for features such as TensorCores and CUDA Dynamic Parallelism as well as a performance visualization tool, AerialVisoin, and an integrated energy model, GPUWattch.},
  howpublished = {gpgpu-sim}
}

@article{GreenTPUImprovingTiming,
  title = {{{GreenTPU}}: {{Improving Timing Error Resilience}} of a {{Near-Threshold Tensor Processing Unit}}},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/YI2V7M8V/GreenTPU Improving Timing Error Resilience of a Near-Threshold Tensor Processing Unit.pdf}
}

@misc{guoMSCeleb1MDatasetBenchmark2016,
  title = {{{MS-Celeb-1M}}: {{A Dataset}} and {{Benchmark}} for {{Large-Scale Face Recognition}}},
  shorttitle = {{{MS-Celeb-1M}}},
  author = {Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  year = {2016},
  month = jul,
  number = {arXiv:1607.08221},
  eprint = {1607.08221},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1607.08221},
  urldate = {2024-03-30},
  abstract = {In this paper, we design a benchmark task and provide the associated datasets for recognizing face images and link them to corresponding entity keys in a knowledge base. More specifically, we propose a benchmark task to recognize one million celebrities from their face images, by using all the possibly collected face images of this individual on the web as training data. The rich information provided by the knowledge base helps to conduct disambiguation and improve the recognition accuracy, and contributes to various real-world applications, such as image captioning and news video analysis. Associated with this task, we design and provide concrete measurement set, evaluation protocol, as well as training data. We also present in details our experiment setup and report promising baseline results. Our benchmark task could lead to one of the largest classification problems in computer vision. To the best of our knowledge, our training dataset, which contains 10M images in version 1, is the largest publicly available one in the world.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Y4VZJ6RR/Guo et al. - 2016 - MS-Celeb-1M A Dataset and Benchmark for Large-Sca.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Q77UBUIX/1607.html}
}

@inproceedings{hadsellDimensionalityReductionLearning2006,
  title = {Dimensionality {{Reduction}} by {{Learning}} an {{Invariant Mapping}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Hadsell, R. and Chopra, S. and LeCun, Y.},
  year = {2006},
  month = jun,
  volume = {2},
  pages = {1735--1742},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.100},
  urldate = {2024-03-30},
  abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that 'similar" points in input space are mapped to nearby points on the manifold. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent nonlinear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distancemeasure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
  keywords = {Astronomy,Biology,Data visualization,Extraterrestrial measurements,Feature extraction,Geoscience,Image analysis,Image generation,Manufacturing industries,Service robots},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/CNRFD37M/1640964.html}
}

@misc{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  number = {arXiv:1512.03385},
  eprint = {1512.03385},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.03385},
  urldate = {2024-03-30},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/PN4FFXIY/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/VSUIAD88/1512.html}
}

@inproceedings{horowitz11ComputingsEnergy2014,
  title = {1.1 {{Computing}}'s Energy Problem (and What We Can Do about It)},
  booktitle = {2014 {{IEEE International Solid-State Circuits Conference Digest}} of {{Technical Papers}} ({{ISSCC}})},
  author = {Horowitz, Mark},
  year = {2014},
  month = feb,
  pages = {10--14},
  publisher = {IEEE},
  address = {San Francisco, CA, USA},
  doi = {10.1109/ISSCC.2014.6757323},
  urldate = {2024-11-28},
  isbn = {978-1-4799-0920-9 978-1-4799-0918-6},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/5WF8JHKJ/Horowitz - 2014 - 1.1 Computing's energy problem (and what we can do about it).pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/T9K4UAPC/Horowitz - 2014 - 1.1 Computing's energy problem (and what we can do about it).pdf}
}

@misc{huertaAnalyzingImprovingHardware2024,
  title = {Analyzing and {{Improving Hardware Modeling}} of {{Accel-Sim}}},
  author = {Huerta, Rodrigo and Shoushtary, Mojtaba Abaie and Gonz{\'a}lez, Antonio},
  year = {2024},
  month = jan,
  number = {arXiv:2401.10082},
  eprint = {2401.10082},
  publisher = {arXiv},
  urldate = {2024-10-26},
  abstract = {GPU architectures have become popular for executing general-purpose programs. Their many-core architecture supports a large number of threads that run concurrently to hide the latency among dependent instructions. In modern GPU architectures, each SM/core is typically composed of several sub-cores, where each sub-core has its own independent pipeline. Simulators are a key tool for investigating novel concepts in computer architecture. They must be performance-accurate and have a proper model related to the target hardware to explore the different bottlenecks properly. This paper presents a wide analysis of different parts of Accel-sim, a popular GPGPU simulator, and some improvements of its model. First, we focus on the front-end and developed a more realistic model. Then, we analyze the way the result bus works and develop a more realistic one. Next, we describe the current memory pipeline model and propose a model for a more cost-effective design. Finally, we discuss other areas of improvement of the simulator.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Hardware Architecture},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/FK7FP6Q6/Huerta et al. - 2024 - Analyzing and Improving Hardware Modeling of Accel-Sim.pdf}
}

@inproceedings{huSqueezeandExcitationNetworks2018,
  title = {Squeeze-and-{{Excitation Networks}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Hu, Jie and Shen, Li and Sun, Gang},
  year = {2018},
  pages = {7132--7141},
  urldate = {2024-03-30},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/YW3WKC9P/Hu et al. - 2018 - Squeeze-and-Excitation Networks.pdf}
}

@misc{huSqueezeandExcitationNetworks2019,
  title = {Squeeze-and-{{Excitation Networks}}},
  author = {Hu, Jie and Shen, Li and Albanie, Samuel and Sun, Gang and Wu, Enhua},
  year = {2019},
  month = may,
  number = {arXiv:1709.01507},
  eprint = {1709.01507},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1709.01507},
  urldate = {2024-03-30},
  abstract = {The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the "Squeeze-and-Excitation" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251\%, surpassing the winning entry of 2016 by a relative improvement of {\textasciitilde}25\%. Models and code are available at https://github.com/hujie-frank/SENet.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/X3JU3XD8/Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/EJ5UG4MD/1709.html}
}

@misc{HW6GPUSimulator,
  title = {{{HW6}}: {{GPU Simulator}}},
  shorttitle = {{{HW6}}},
  journal = {HackMD},
  urldate = {2024-10-26},
  abstract = {\# HW6: GPU Simulator   \#\# Introduction GPGPU-Sim (General Purpose Graphics Processing Unit Simulator},
  howpublished = {https://hackmd.io/@ipc23/hw6},
  langid = {american},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/AALDHI7M/hw6.html}
}

@misc{jiaDissectingNVIDIAVolta2018,
  title = {Dissecting the {{NVIDIA Volta GPU Architecture}} via {{Microbenchmarking}}},
  author = {Jia, Zhe and Maggioni, Marco and Staiger, Benjamin and Scarpazza, Daniele P.},
  year = {2018},
  month = apr,
  number = {arXiv:1804.06826},
  eprint = {1804.06826},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1804.06826},
  urldate = {2025-07-05},
  abstract = {Every year, novel NVIDIA GPU designs are introduced. This rapid architectural and technological progression, coupled with a reluctance by manufacturers to disclose low-level details, makes it difficult for even the most proficient GPU software designers to remain up-to-date with the technological advances at a microarchitectural level. To address this dearth of public, microarchitectural-level information on the novel NVIDIA GPUs, independent researchers have resorted to microbenchmarks-based dissection and discovery. This has led to a prolific line of publications that shed light on instruction encoding, and memory hierarchy's geometry and features at each level. Namely, research that describes the performance and behavior of the Kepler, Maxwell and Pascal architectures. In this technical report, we continue this line of research by presenting the microarchitectural details of the NVIDIA Volta architecture, discovered through microbenchmarks and instruction set disassembly. Additionally, we compare quantitatively our Volta findings against its predecessors, Kepler, Maxwell and Pascal.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Performance,GPU,Microbenchmarking,Volta},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/FX66U3YG/Jia et al. - 2018 - Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/QZ39JIDY/1804.html}
}

@article{jouppiDomainspecificSupercomputerTraining2020,
  title = {A Domain-Specific Supercomputer for Training Deep Neural Networks},
  author = {Jouppi, Norman P. and Yoon, Doe Hyun and Kurian, George and Li, Sheng and Patil, Nishant and Laudon, James and Young, Cliff and Patterson, David},
  year = {2020},
  month = jun,
  journal = {Communications of the ACM},
  volume = {63},
  number = {7},
  pages = {67--78},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3360307},
  urldate = {2024-12-10},
  abstract = {Google's TPU supercomputers train deep neural networks 50x faster than general-purpose supercomputers running a high-performance computing benchmark.},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/X4HGMZ9A/Jouppi et al. - 2020 - A domain-specific supercomputer for training deep neural networks.pdf}
}

@misc{jouppiInDatacenterPerformanceAnalysis2017,
  title = {In-{{Datacenter Performance Analysis}} of a {{Tensor Processing Unit}}},
  author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  year = {2017},
  month = apr,
  number = {arXiv:1704.04760},
  eprint = {1704.04760},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1704.04760},
  urldate = {2025-01-23},
  abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU)---deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs (caches, out-of-order execution, multithreading, multiprocessing, prefetching, ...) that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level TensorFlow framework, uses production NN applications (MLPs, CNNs, and LSTMs) that represent 95\% of our datacenters' NN inference demand. Despite low utilization for some applications, the TPU is on average about 15X - 30X faster than its contemporary GPU or CPU, with TOPS/Watt about 30X - 80X higher. Moreover, using the GPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/C5D73ZKK/Jouppi et al. - 2017 - In-Datacenter Performance Analysis of a Tensor Processing Unit.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/PZNNRR4U/1704.html}
}

@inproceedings{jouppiTPUV4Optically2023,
  title = {{{TPU}} v4: {{An Optically Reconfigurable Supercomputer}} for {{Machine Learning}} with {{Hardware Support}} for {{Embeddings}}},
  shorttitle = {{{TPU}} V4},
  booktitle = {Proceedings of the 50th {{Annual International Symposium}} on {{Computer Architecture}}},
  author = {Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
  year = {2023},
  month = jun,
  pages = {1--14},
  publisher = {ACM},
  address = {Orlando FL USA},
  doi = {10.1145/3579371.3589350},
  urldate = {2024-12-09},
  isbn = {979-8-4007-0095-8},
  langid = {english}
}

@inproceedings{jouppiTPUV4Optically2023a,
  title = {{{TPU}} v4: {{An Optically Reconfigurable Supercomputer}} for {{Machine Learning}} with {{Hardware Support}} for {{Embeddings}}},
  shorttitle = {{{TPU}} V4},
  booktitle = {Proceedings of the 50th {{Annual International Symposium}} on {{Computer Architecture}}},
  author = {Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
  year = {2023},
  month = jun,
  pages = {1--14},
  publisher = {ACM},
  address = {Orlando FL USA},
  doi = {10.1145/3579371.3589350},
  urldate = {2024-12-09},
  isbn = {979-8-4007-0095-8},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/XSBQQ4QL/Jouppi et al. - 2023 - TPU v4 An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Emb.pdf}
}

@misc{kachrisSurveyHardwareAccelerators2024,
  title = {A {{Survey}} on {{Hardware Accelerators}} for {{Large Language Models}}},
  author = {Kachris, Christoforos},
  year = {2024},
  month = jan,
  number = {arXiv:2401.09890},
  eprint = {2401.09890},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.09890},
  urldate = {2024-10-26},
  abstract = {Large Language Models (LLMs) have emerged as powerful tools for natural language processing tasks, revolutionizing the field with their ability to understand and generate human-like text. As the demand for more sophisticated LLMs continues to grow, there is a pressing need to address the computational challenges associated with their scale and complexity. This paper presents a comprehensive survey on hardware accelerators designed to enhance the performance and energy efficiency of Large Language Models. By examining a diverse range of accelerators, including GPUs, FPGAs, and custom-designed architectures, we explore the landscape of hardware solutions tailored to meet the unique computational demands of LLMs. The survey encompasses an in-depth analysis of architecture, performance metrics, and energy efficiency considerations, providing valuable insights for researchers, engineers, and decision-makers aiming to optimize the deployment of LLMs in real-world applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Hardware Architecture,Computer Science - Machine Learning},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/HYF662CQ/Kachris - 2024 - A Survey on Hardware Accelerators for Large Language Models.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/EPKSFQHK/2401.html}
}

@misc{kolliasAffWild2ExtendingAffWild2019,
  title = {Aff-{{Wild2}}: {{Extending}} the {{Aff-Wild Database}} for {{Affect Recognition}}},
  shorttitle = {Aff-{{Wild2}}},
  author = {Kollias, Dimitrios and Zafeiriou, Stefanos},
  year = {2019},
  month = dec,
  number = {arXiv:1811.07770},
  eprint = {1811.07770},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1811.07770},
  urldate = {2024-03-31},
  abstract = {Automatic understanding of human affect using visual signals is a problem that has attracted significant interest over the past 20 years. However, human emotional states are quite complex. To appraise such states displayed in real-world settings, we need expressive emotional descriptors that are capable of capturing and describing this complexity. The circumplex model of affect, which is described in terms of valence (i.e., how positive or negative is an emotion) and arousal (i.e., power of the activation of the emotion), can be used for this purpose. Recent progress in the emotion recognition domain has been achieved through the development of deep neural architectures and the availability of very large training databases. To this end, Aff-Wild has been the first large-scale "in-the-wild" database, containing around 1,200,000 frames. In this paper, we build upon this database, extending it with 260 more subjects and 1,413,000 new video frames. We call the union of Aff-Wild with the additional data, Aff-Wild2. The videos are downloaded from Youtube and have large variations in pose, age, illumination conditions, ethnicity and profession. Both database-specific as well as cross-database experiments are performed in this paper, by utilizing the Aff-Wild2, along with the RECOLA database. The developed deep neural architectures are based on the joint training of state-of-the-art convolutional and recurrent neural networks with attention mechanism; thus exploiting both the invariant properties of convolutional features, while modeling temporal dynamics that arise in human behaviour via the recurrent layers. The obtained results show premise for utilization of the extended Aff-Wild, as well as of the developed deep neural architectures for visual analysis of human behaviour in terms of continuous emotion dimensions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/X5IEA9S4/Kollias and Zafeiriou - 2019 - Aff-Wild2 Extending the Aff-Wild Database for Aff.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/IC2JDPKX/1811.html}
}

@misc{lewAnalyzingMachineLearning2019,
  title = {Analyzing {{Machine Learning Workloads Using}} a {{Detailed GPU Simulator}}},
  author = {Lew, Jonathan and Shah, Deval and Pati, Suchita and Cattell, Shaylin and Zhang, Mengchi and Sandhupatla, Amruth and Ng, Christopher and Goli, Negar and Sinclair, Matthew D. and Rogers, Timothy G. and Aamodt, Tor},
  year = {2019},
  month = jan,
  number = {arXiv:1811.08933},
  eprint = {1811.08933},
  publisher = {arXiv},
  urldate = {2024-10-26},
  abstract = {Most deep neural networks deployed today are trained using GPUs via high-level frameworks such as TensorFlow and PyTorch. This paper describes changes we made to the GPGPU-Sim simulator to enable it to run PyTorch by running PTX kernels included in NVIDIA's cuDNN library. We use the resulting modified simulator, which has been made available publicly with this paper, to study some simple deep learning workloads. With our changes to GPGPU-Sim's functional simulation model, we find GPGPU-Sim performance model running a cuDNN enabled implementation of LeNet for MNIST reports results within 30\% of real hardware. Using GPGPU-Sim's AerialVision performance analysis tool we observe that cuDNN API calls contain many varying phases and appear to include potentially inefficient microarchitecture behaviour such as DRAM partition bank camping, at least when executed on GPGPU-Sim's current performance model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/EUUSPK3P/Analyzing Machine Learning Workloads Using a  Detailed GPU Simulator.pdf}
}

@misc{liuDABDETRDynamicAnchor2022,
  title = {{{DAB-DETR}}: {{Dynamic Anchor Boxes}} Are {{Better Queries}} for {{DETR}}},
  shorttitle = {{{DAB-DETR}}},
  author = {Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
  year = {2022},
  month = mar,
  number = {arXiv:2201.12329},
  eprint = {2201.12329},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.12329},
  urldate = {2024-03-30},
  abstract = {We present in this paper a novel query formulation using dynamic anchor boxes for DETR (DEtection TRansformer) and offer a deeper understanding of the role of queries in DETR. This new formulation directly uses box coordinates as queries in Transformer decoders and dynamically updates them layer-by-layer. Using box coordinates not only helps using explicit positional priors to improve the query-to-feature similarity and eliminate the slow training convergence issue in DETR, but also allows us to modulate the positional attention map using the box width and height information. Such a design makes it clear that queries in DETR can be implemented as performing soft ROI pooling layer-by-layer in a cascade manner. As a result, it leads to the best performance on MS-COCO benchmark among the DETR-like detection models under the same setting, e.g., AP 45.7{\textbackslash}\% using ResNet50-DC5 as backbone trained in 50 epochs. We also conducted extensive experiments to confirm our analysis and verify the effectiveness of our methods. Code is available at {\textbackslash}url\{https://github.com/SlongLiu/DAB-DETR\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/GSJDZDT8/Liu et al. - 2022 - DAB-DETR Dynamic Anchor Boxes are Better Queries .pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/FWBRMPZE/2201.html}
}

@misc{liuMAFWLargescaleMultimodal2023,
  title = {{{MAFW}}: {{A Large-scale}}, {{Multi-modal}}, {{Compound Affective Database}} for {{Dynamic Facial Expression Recognition}} in the {{Wild}}},
  shorttitle = {{{MAFW}}},
  author = {Liu, Yuanyuan and Dai, Wei and Feng, Chuanxu and Wang, Wenbin and Yin, Guanghao and Zeng, Jiabei and Shan, Shiguang},
  year = {2023},
  month = aug,
  number = {arXiv:2208.00847},
  eprint = {2208.00847},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.00847},
  urldate = {2024-03-31},
  abstract = {Dynamic facial expression recognition (FER) databases provide important data support for affective computing and applications. However, most FER databases are annotated with several basic mutually exclusive emotional categories and contain only one modality, e.g., videos. The monotonous labels and modality cannot accurately imitate human emotions and fulfill applications in the real world. In this paper, we propose MAFW, a large-scale multi-modal compound affective database with 10,045 video-audio clips in the wild. Each clip is annotated with a compound emotional category and a couple of sentences that describe the subjects' affective behaviors in the clip. For the compound emotion annotation, each clip is categorized into one or more of the 11 widely-used emotions, i.e., anger, disgust, fear, happiness, neutral, sadness, surprise, contempt, anxiety, helplessness, and disappointment. To ensure high quality of the labels, we filter out the unreliable annotations by an Expectation Maximization (EM) algorithm, and then obtain 11 single-label emotion categories and 32 multi-label emotion categories. To the best of our knowledge, MAFW is the first in-the-wild multi-modal database annotated with compound emotion annotations and emotion-related captions. Additionally, we also propose a novel Transformer-based expression snippet feature learning method to recognize the compound emotions leveraging the expression-change relations among different emotions and modalities. Extensive experiments on MAFW database show the advantages of the proposed method over other state-of-the-art methods for both uni- and multi-modal FER. Our MAFW database is publicly available from https://mafw-database.github.io/MAFW.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/87IV259H/Liu et al. - 2023 - MAFW A Large-scale, Multi-modal, Compound Affecti.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/43YILRZN/2208.html}
}

@inproceedings{liuSphereFaceDeepHypersphere2017,
  title = {{{SphereFace}}: {{Deep Hypersphere Embedding}} for {{Face Recognition}}},
  shorttitle = {{{SphereFace}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Li, Ming and Raj, Bhiksha and Song, Le},
  year = {2017},
  pages = {212--220},
  urldate = {2024-03-30},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/6GR5UWAQ/Liu et al. - 2017 - SphereFace Deep Hypersphere Embedding for Face Re.pdf}
}

@inproceedings{liuSwinTransformerHierarchical2021,
  title = {Swin {{Transformer}}: {{Hierarchical Vision Transformer Using Shifted Windows}}},
  shorttitle = {Swin {{Transformer}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  year = {2021},
  pages = {10012--10022},
  urldate = {2024-03-30},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/HVXF58UB/Liu et al. - 2021 - Swin Transformer Hierarchical Vision Transformer .pdf}
}

@misc{luoDissectingNVIDIAHopper2025,
  title = {Dissecting the {{NVIDIA Hopper Architecture}} through {{Microbenchmarking}} and {{Multiple Level Analysis}}},
  author = {Luo, Weile and Fan, Ruibo and Li, Zeyu and Du, Dayou and Liu, Hongyuan and Wang, Qiang and Chu, Xiaowen},
  year = {2025},
  month = jan,
  number = {arXiv:2501.12084},
  eprint = {2501.12084},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.12084},
  urldate = {2025-01-25},
  abstract = {Modern GPUs, with their specialized hardware like tensor cores, are essential for demanding AI and deep learning applications. This study presents a comprehensive, multi-level microbenchmarking analysis of the NVIDIA Hopper GPU architecture, delving into its performance characteristics and novel features. We benchmark Hopper's memory subsystem latency and throughput, comparing its L2 partitioned cache behavior and global memory access patterns against recent GPU generations, Ampere and Ada Lovelace. Our analysis reveals significant performance differences and architectural improvements in Hopper. A core contribution of this work is a detailed evaluation of Hopper's fourth-generation tensor cores, including their FP8 precision support and the novel asynchronous wgmma instructions, assessing their impact on matrix multiply-accumulate operations. We further investigate the performance implications of other key Hopper innovations: DPX instructions for accelerating dynamic programming algorithms, distributed shared memory (DSM) for inter-SM communication, and the Tensor Memory Accelerator (TMA) for asynchronous data movement. This multi-level approach encompasses instruction-level microbenchmarks, library-level analysis of the Transformer Engine, and application-level benchmarks of tensor core performance within large language models. Our findings provide valuable, in-depth insights for software developers seeking to optimize performance and develop accurate performance models for the Hopper architecture, ultimately contributing to a deeper understanding of its potential for accelerating AI and other computationally intensive workloads.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Hardware Architecture,Computer Science - Performance},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Q486FLEZ/Luo et al. - 2025 - Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis.pdf}
}

@misc{massonFlipHashConstantTimeConsistent2024,
  title = {{{FlipHash}}: {{A Constant-Time Consistent Range-Hashing Algorithm}}},
  shorttitle = {{{FlipHash}}},
  author = {Masson, Charles and Lee, Homin K.},
  year = {2024},
  month = feb,
  number = {arXiv:2402.17549},
  eprint = {2402.17549},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.17549},
  urldate = {2024-04-04},
  abstract = {Consistent range-hashing is a technique used in distributed systems, either directly or as a subroutine for consistent hashing, commonly to realize an even and stable data distribution over a variable number of resources. We introduce FlipHash, a consistent range-hashing algorithm with constant time complexity and low memory requirements. Like Jump Consistent Hash, FlipHash is intended for applications where resources can be indexed sequentially. Under this condition, it ensures that keys are hashed evenly across resources and that changing the number of resources only causes keys to be remapped from a removed resource or to an added one, but never shuffled across persisted ones. FlipHash differentiates itself with its low computational cost, achieving constant-time complexity. We show that FlipHash beats Jump Consistent Hash's cost, which is logarithmic in the number of resources, both theoretically and in experiments over practical settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,E.1,E.2},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/5WA6XBZ7/Masson and Lee - 2024 - FlipHash A Constant-Time Consistent Range-Hashing.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/M9M838YU/2402.html}
}

@article{mauriziocorbettaControlGoaldirectedStimulusdriven2002,
  title = {Control of Goal-Directed and Stimulus-Driven Attention in the Brain},
  author = {{Maurizio Corbetta} and {Gordon L. Shulman}},
  year = {2002},
  month = mar,
  journal = {Nature Reviews Neuroscience},
  volume = {3},
  number = {3},
  pages = {201--215},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn755},
  urldate = {2024-03-30},
  copyright = {https://www.springer.com/tdm},
  langid = {english}
}

@article{mittalSurveyHardwareAccelerators2021,
  title = {A Survey {{On}} Hardware Accelerators and Optimization Techniques for {{RNNs}}},
  author = {Mittal, Sparsh and Umesh, Sumanth},
  year = {2021},
  month = jan,
  journal = {Journal of Systems Architecture},
  volume = {112},
  pages = {101839},
  issn = {1383-7621},
  doi = {10.1016/j.sysarc.2020.101839},
  urldate = {2024-10-26},
  abstract = {``Recurrent neural networks'' (RNNs) are powerful artificial intelligence models that have shown remarkable effectiveness in several tasks such as music generation, speech recognition and machine translation. RNN computations involve both intra-timestep and inter-timestep dependencies. Due to these features, hardware acceleration of RNNs is more challenging than that of CNNs. Recently, several researchers have proposed hardware architectures for RNNs. In this paper, we present a survey of GPU/FPGA/ASIC-based accelerators and optimization techniques for RNNs. We highlight the key ideas of different techniques to bring out their similarities and differences. Improvements in deep-learning algorithms have inevitably gone hand-in-hand with the improvements in the hardware-accelerators. Nevertheless, there is a need and scope of even greater synergy between these two fields. This survey seeks to synergize the efforts of researchers in the area of deep learning, computer architecture, and chip-design.},
  keywords = {ASIC,Deep learning,FPGA,GPU,Low-precision,Parallelization,Pruning,Recurrent neural networks}
}

@article{mohaidatSurveyNeuralNetwork2024,
  title = {A {{Survey}} on {{Neural Network Hardware Accelerators}}},
  author = {Mohaidat, Tamador and Khalil, Kasem},
  year = {2024},
  month = aug,
  journal = {IEEE Transactions on Artificial Intelligence},
  volume = {5},
  number = {8},
  pages = {3801--3822},
  issn = {2691-4581},
  doi = {10.1109/TAI.2024.3377147},
  urldate = {2024-10-26},
  abstract = {Artificial intelligence (AI) hardware accelerator is an emerging research for several applications and domains. The hardware accelerator's direction is to provide high computational speed with retaining low-cost and high learning performance. The main challenge is to design complex machine learning models on hardware with high performance. This article presents a thorough investigation into machine learning accelerators and associated challenges. It describes a hardware implementation of different structures such as convolutional neural network (CNN), recurrent neural network (RNN), and artificial neural network (ANN). The challenges such as speed, area, resource consumption, and throughput are discussed. It also presents a comparison between the existing hardware design. Last, the article describes the evaluation parameters for a machine learning accelerator in terms of learning and testing performance and hardware design.},
  keywords = {Artificial intelligence,Artificial intelligence (AI),artificial neural network (ANN),convolutional neural network (CNN),Costs,Hardware acceleration,hardware accelerator,machine learning,Machine learning,machine learning design,machine learning on-chip,neural network,Performance evaluation,Power demand,recurrent neural network (RNN),Throughput},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/XR6NPZFV/10472723.html}
}

@article{nickelSurveyArchitecturesHardware2024,
  title = {A {{Survey}} on {{Architectures}}, {{Hardware Acceleration}} and {{Challenges}} for {{In-Network Computing}}},
  author = {Nickel, Matthias and G{\"o}hringer, Diana},
  year = {2024},
  month = oct,
  journal = {ACM Trans. Reconfigurable Technol. Syst.},
  issn = {1936-7406},
  doi = {10.1145/3699514},
  urldate = {2024-10-26},
  abstract = {By moving data and computation away from the end user to more powerful servers in the cloud or to cloudlets at the edge, end user devices only need to compute locally for small amounts of data and when low latency is required. However, with the advent of 6G and Internet-of-Everything, the demand for more powerful networks continues to grow. The introduction of Software-Defined Networking and Network Function Virtualization has allowed us to rethink networks and use them for more than just routing data to servers. In addition, the use of more powerful network devices is bringing new life to the concept of active networks in the form of in-network computing. In-Network Computing provides the ability to move applications into the network and process data on programmable network devices as they are transmitted. In this work, we provide an overview of in-network computing and its enabling technologies. We take a look at the programmability and different hardware architectures for SmartNICs and switches, focusing primarily on accelerators such as FPGAs. We discuss the state of the art and challenges in this area, and look at CGRAs, a class of hardware accelerators that hase not been widely discussed in this context.},
  annotation = {Just Accepted}
}

@article{nickelSurveyArchitecturesHardware2024a,
  title = {A {{Survey}} on {{Architectures}}, {{Hardware Acceleration}} and {{Challenges}} for {{In-Network Computing}}},
  author = {Nickel, Matthias and G{\"o}hringer, Diana},
  year = {2024},
  month = oct,
  journal = {ACM Transactions on Reconfigurable Technology and Systems},
  pages = {3699514},
  issn = {1936-7406, 1936-7414},
  doi = {10.1145/3699514},
  urldate = {2024-10-26},
  abstract = {By moving data and computation away from the end user to more powerful servers in the cloud or to cloudlets at the edge, end user devices only need to compute locally for small amounts of data and when low latency is required. However, with the advent of 6G and Internet-of-Everything, the demand for more powerful networks continues to grow. The introduction of Software-Defined Networking and Network Function Virtualization has allowed us to rethink networks and use them for more than just routing data to servers. In addition, the use of more powerful network devices is bringing new life to the concept of active networks in the form of in-network computing. In-Network Computing provides the ability to move applications into the network and process data on programmable network devices as they are transmitted. In this work, we provide an overview of in-network computing and its enabling technologies. We take a look at the programmability and different hardware architectures for SmartNICs and switches, focusing primarily on accelerators such as FPGAs. We discuss the state of the art and challenges in this area, and look at CGRAs, a class of hardware accelerators that hase not been widely discussed in this context.},
  langid = {english}
}

@article{ningJWSAAJointWeak2021,
  title = {{{JWSAA}}: {{Joint}} Weak Saliency and Attention Aware for Person Re-Identification},
  shorttitle = {{{JWSAA}}},
  author = {Ning, Xin and Gong, Ke and Li, Weijun and Zhang, Liping},
  year = {2021},
  month = sep,
  journal = {Neurocomputing},
  volume = {453},
  pages = {801--811},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.05.106},
  urldate = {2024-03-30},
  abstract = {Attention mechanisms can extract salient features in images, which has been proven to be effective for person re-identification. However, focusing on the saliency of an image is not enough. On the one hand, the salient features extracted from the model are not necessarily the features needed, e.g., a similar background may also be mistaken as salient features; on the other hand, various salient features are often more conducive to improving the performance of the model. Based on this, in this paper, a model that has joint weak saliency and attention aware is proposed, which can obtain more complete global features by weakening saliency features. The model then obtains diversified saliency features via attention diversity to improve the performance of the model. Experiments on commonly used datasets prove the effectiveness of the proposed method.},
  keywords = {Attention mechanism,Deep neural networks,Person re-identification,Saliency features},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/M293GEMP/S0925231220313606.html}
}

@book{paulekmanWhatFaceReveals1997,
  title = {What the Face Reveals:  {{Basic}} and Applied Studies of Spontaneous Expression Using the {{Facial Action Coding System}} ({{FACS}})},
  shorttitle = {What the Face Reveals},
  editor = {{Paul Ekman} and {Erika L. Rosenberg}},
  year = {1997},
  series = {What the Face Reveals:  {{Basic}} and Applied Studies of Spontaneous Expression Using the {{Facial Action Coding System}} ({{FACS}})},
  pages = {xvi, 495},
  publisher = {Oxford University Press},
  address = {New York, NY, US},
  abstract = {This book presents previously published articles on spontaneous facial expression in a single volume, so that they may be more accessible to interested scholars and practitioners.  This book is divided into 2 major parts: one on basic research and another on applied research. Part I consists mainly of research relevant to the psychology of emotion, but it also includes basic research on related topics---namely, deception and pain. Part II presents studies in which facial measures were examined in relation to mental or physical health variables. Many of the studies in Part II show that facial expression variables prove to be useful in discriminating among diagnostic groups. Within each part, each chapter consists of a reprinted article, followed by a brief afterword by the authors of the original piece. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-19-510446-2 978-0-19-510447-9},
  keywords = {Facial Expressions,Measurement},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/35G8JKD2/1998-07552-000.html}
}

@article{peccerilloSurveyHardwareAccelerators2022,
  title = {A Survey on Hardware Accelerators: {{Taxonomy}}, Trends, Challenges, and Perspectives},
  shorttitle = {A Survey on Hardware Accelerators},
  author = {Peccerillo, Biagio and Mannino, Mirco and Mondelli, Andrea and Bartolini, Sandro},
  year = {2022},
  month = aug,
  journal = {Journal of Systems Architecture},
  volume = {129},
  pages = {102561},
  issn = {1383-7621},
  doi = {10.1016/j.sysarc.2022.102561},
  urldate = {2024-10-26},
  abstract = {In recent years, the limits of the multicore approach emerged in the so-called ``dark silicon'' issue and diminishing returns of an ever-increasing core count. Hardware manufacturers, out of necessity, switched their focus to accelerators, a new paradigm that pursues specialization and heterogeneity over generality and homogeneity. They are special-purpose hardware structures separated from the CPU with aspects that exhibit a high degree of variability. We define a taxonomy based on fourteen of these aspects, grouped in four macro-categories: general aspects, host coupling, architecture, and software aspects. According to it, we categorize around 100 accelerators of the last decade from both industry and academia, and critically analyze emerging trends. We complete our discussion with throughput and efficiency figures. Then, we discuss some prominent open challenges that accelerators are facing, analyzing state-of-the-art solutions, and suggesting prospective research directions for the future.},
  keywords = {Accelerators,CGRA,Classification,Data-parallel,Domain-Specific Architectures,Future research directions,Machine Learning,Open challenges,PIM,Survey,Taxonomy},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/BJ6NY2CN/Peccerillo et al. - 2022 - A survey on hardware accelerators Taxonomy, trends, challenges, and perspectives.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/PDE8REHM/S1383762122001138.html}
}

@inproceedings{poutievskiJupiterEvolvingTransforming2022,
  title = {Jupiter Evolving: Transforming Google's Datacenter Network via Optical Circuit Switches and Software-Defined Networking},
  shorttitle = {Jupiter Evolving},
  booktitle = {Proceedings of the {{ACM SIGCOMM}} 2022 {{Conference}}},
  author = {Poutievski, Leon and Mashayekhi, Omid and Ong, Joon and Singh, Arjun and Tariq, Mukarram and Wang, Rui and Zhang, Jianan and Beauregard, Virginia and Conner, Patrick and Gribble, Steve and Kapoor, Rishi and Kratzer, Stephen and Li, Nanfang and Liu, Hong and Nagaraj, Karthik and Ornstein, Jason and Sawhney, Samir and Urata, Ryohei and Vicisano, Lorenzo and Yasumura, Kevin and Zhang, Shidong and Zhou, Junlan and Vahdat, Amin},
  year = {2022},
  month = aug,
  series = {{{SIGCOMM}} '22},
  pages = {66--85},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544216.3544265},
  urldate = {2025-01-23},
  abstract = {We present a decade of evolution and production experience with Jupiter datacenter network fabrics. In this period Jupiter has delivered 5x higher speed and capacity, 30\% reduction in capex, 41\% reduction in power, incremental deployment and technology refresh all while serving live production traffic. A key enabler for these improvements is evolving Jupiter from a Clos to a direct-connect topology among the machine aggregation blocks. Critical architectural changes for this include: A datacenter interconnection layer employing Micro-Electro-Mechanical Systems (MEMS) based Optical Circuit Switches (OCSes) to enable dynamic topology reconfiguration, centralized Software-Defined Networking (SDN) control for traffic engineering, and automated network operations for incremental capacity delivery and topology engineering. We show that the combination of traffic and topology engineering on direct-connect fabrics achieves similar throughput as Clos fabrics for our production traffic patterns. We also optimize for path lengths: 60\% of the traffic takes direct path from source to destination aggregation blocks, while the remaining transits one additional block, achieving an average block-level path length of 1.4 in our fleet today. OCS also achieves 3x faster fabric reconfiguration compared to pre-evolution Clos fabrics that used a patch panel based interconnect.},
  isbn = {978-1-4503-9420-8},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/BYXHCHG7/Jupiter Evolving Transforming Googles Datacenter Network via Optical Circuit Switches and Software-Defined Networking.pdf}
}

@misc{qinFcaNetFrequencyChannel2021,
  title = {{{FcaNet}}: {{Frequency Channel Attention Networks}}},
  shorttitle = {{{FcaNet}}},
  author = {Qin, Zequn and Zhang, Pengyi and Wu, Fei and Li, Xi},
  year = {2021},
  month = jul,
  number = {arXiv:2012.11879},
  eprint = {2012.11879},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2012.11879},
  urldate = {2024-03-30},
  abstract = {Attention mechanism, especially channel attention, has gained great success in the computer vision field. Many works focus on how to design efficient channel attention mechanisms while ignoring a fundamental problem, i.e., channel attention mechanism uses scalar to represent channel, which is difficult due to massive information loss. In this work, we start from a different view and regard the channel representation problem as a compression process using frequency analysis. Based on the frequency analysis, we mathematically prove that the conventional global average pooling is a special case of the feature decomposition in the frequency domain. With the proof, we naturally generalize the compression of the channel attention mechanism in the frequency domain and propose our method with multi-spectral channel attention, termed as FcaNet. FcaNet is simple but effective. We can change a few lines of code in the calculation to implement our method within existing channel attention methods. Moreover, the proposed method achieves state-of-the-art results compared with other channel attention methods on image classification, object detection, and instance segmentation tasks. Our method could consistently outperform the baseline SENet, with the same number of parameters and the same computational cost. Our code and models will are publicly available at https://github.com/cfzd/FcaNet.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/TA428XFI/Qin et al. - 2021 - FcaNet Frequency Channel Attention Networks.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/P67X2Q35/2012.html}
}

@article{qinSwinFaceMultitaskTransformer2024,
  title = {{{SwinFace}}: {{A Multi-task Transformer}} for {{Face Recognition}}, {{Expression Recognition}}, {{Age Estimation}} and {{Attribute Estimation}}},
  shorttitle = {{{SwinFace}}},
  author = {Qin, Lixiong and Wang, Mei and Deng, Chao and Wang, Ke and Chen, Xi and Hu, Jiani and Deng, Weihong},
  year = {2024},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  eprint = {2308.11509},
  primaryclass = {cs},
  pages = {1--1},
  issn = {1051-8215, 1558-2205},
  doi = {10.1109/TCSVT.2023.3304724},
  urldate = {2024-03-30},
  abstract = {In recent years, vision transformers have been introduced into face recognition and analysis and have achieved performance breakthroughs. However, most previous methods generally train a single model or an ensemble of models to perform the desired task, which ignores the synergy among different tasks and fails to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper presents a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, the SwinFace, consists of a single shared backbone together with a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97\% accuracy on RAF-DB and 0.22 \${\textbackslash}epsilon\$-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. The code and models will be made publicly available at https://github.com/lxq1000/SwinFace.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/XVZC4SZW/Qin et al. - 2024 - SwinFace A Multi-task Transformer for Face Recogn.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/JPVTHP9C/2308.html}
}

@inproceedings{raoSparseCoreStreamISA2022,
  title = {{{SparseCore}}: Stream {{ISA}} and Processor Specialization for Sparse Computation},
  shorttitle = {{{SparseCore}}},
  booktitle = {Proceedings of the 27th {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}},
  author = {Rao, Gengyu and Chen, Jingji and Yik, Jason and Qian, Xuehai},
  year = {2022},
  month = feb,
  pages = {186--199},
  publisher = {ACM},
  address = {Lausanne Switzerland},
  doi = {10.1145/3503222.3507705},
  urldate = {2024-12-10},
  isbn = {978-1-4503-9205-1},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/U4HDWR7B/Rao et al. - 2022 - SparseCore stream ISA and processor specialization for sparse computation.pdf}
}

@book{raschkaMachineLearningPyTorch2022,
  title = {Machine Learning with {{PyTorch}} and {{Scikit-Learn}}: Develop Machine Learning and Deep Learning Models with {{Python}}},
  shorttitle = {Machine Learning with {{PyTorch}} and {{Scikit-Learn}}},
  author = {Raschka, Sebastian and Liu, Yuxi and Mirjalili, Vahid and Dzhulgakov, Dmytro},
  year = {2022},
  series = {Expert Insight},
  publisher = {Packt},
  address = {Birmingham Mumbai},
  abstract = {This book of the bestselling and widely acclaimed Python Machine Learning series is a comprehensive guide to machine and deep learning using PyTorch's simple to code framework.Purchase of the print or Kindle book includes a free eBook in PDF format.Key FeaturesLearn applied machine learning with a solid foundation in theoryClear, intuitive explanations take you deep into the theory and practice of Python machine learningFully updated and expanded to cover PyTorch, transformers, XGBoost, graph neural networks, and best practicesBook DescriptionMachine Learning with PyTorch and Scikit-Learn is a comprehensive guide to machine learning and deep learning with PyTorch. It acts as both a step-by-step tutorial and a reference you'll keep coming back to as you build your machine learning systems.Packed with clear explanations, visualizations, and examples, the book covers all the essential machine learning techniques in depth. While some books teach you only to follow instructions, with this machine learning book, we teach the principles allowing you to build models and applications for yourself.Why PyTorch?PyTorch is the Pythonic way to learn machine learning, making it easier to learn and simpler to code with. This book explains the essential parts of PyTorch and how to create models using popular libraries, such as PyTorch Lightning and PyTorch Geometric.You will also learn about generative adversarial networks (GANs) for generating new data and training intelligent agents with reinforcement learning. Finally, this new edition is expanded to cover the latest trends in deep learning, including graph neural networks and large-scale transformers used for natural language processing (NLP).This PyTorch book is your companion to machine learning with Python, whether you're a Python developer new to machine learning or want to deepen your knowledge of the latest developments.What you will learnExplore frameworks, models, and techniques for machines to 'learn' from dataUse scikit-learn for machine learning and PyTorch for deep learningTrain machine learning classifiers on images, text, and moreBuild and train neural networks, transformers, and boosting algorithmsDiscover best practices for evaluating and tuning modelsPredict continuous target outcomes using regression analysisDig deeper into textual and social media data using sentiment analysisWho this book is forIf you have a good grasp of Python basics and want to start learning about machine learning and deep learning, then this is the book for you. This is an essential resource written for developers and data scientists who want to create practical machine learning and deep learning applications using scikit-learn and PyTorch.Before you get started with this book, you'll need a good understanding of calculus, as well as linear algebra},
  isbn = {978-1-80181-931-2},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/7SDFZ6N3/Raschka et al. - 2022 - Machine learning with PyTorch and Scikit-Learn de.pdf}
}

@misc{RecentDevelopmentsLowPower,
  title = {Recent {{Developments}} in {{Low-Power AI Accelerators}}: {{A Survey}}},
  urldate = {2024-10-26},
  howpublished = {https://www.mdpi.com/1999-4893/15/11/419},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/48IHIE96/algorithms-15-00419-with-cover.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/PLXDGR4Z/419.html}
}

@article{rensinkDynamicRepresentationScenes2000,
  title = {The Dynamic Representation of Scenes},
  author = {Rensink, Ronald A.},
  year = {2000},
  journal = {Visual Cognition},
  volume = {7},
  number = {1-3},
  pages = {17--42},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1464-0716},
  doi = {10.1080/135062800394667},
  abstract = {Argues that focused attention provides spatiotemporal coherence for the stable representation of one object at a time. It is proposed that a dynamic representation underlies perception of scenes. One component of this proposal is a coherence theory of attention, which asserts that unattended structures are volatile, and that focused attention is needed to stabilize them sufficiently to allow the perception of change. The other component is the assertion that vision makes use of virtual representation, a dynamic form of representation in which attention provides detailed, coherent descriptions of objects that are needed exactly when they are needed. A triadic architecture is proposed as one possible way to create such a representation. This architecture uses representations that are stable and representations that contain large amounts of visual detail. But at no point does it use representations that are both stable and contain large amounts of detail. In this view, the impression of having representations that are both stable and detailed is due to the careful coordination of attention. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Theories,Visual Perception},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/W2HSZXIW/Rensink - 2000 - The dynamic representation of scenes.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Z9FGUGHW/2000-13795-002.html}
}

@misc{reutherAIMLAccelerator2022,
  title = {{{AI}} and {{ML Accelerator Survey}} and {{Trends}}},
  author = {Reuther, Albert and Michaleas, Peter and Jones, Michael and Gadepally, Vijay and Samsi, Siddharth and Kepner, Jeremy},
  year = {2022},
  month = oct,
  number = {arXiv:2210.04055},
  eprint = {2210.04055},
  publisher = {arXiv},
  urldate = {2024-10-26},
  abstract = {This paper updates the survey of AI accelerators and processors from past three years. This paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. Two new trends plots based on accelerator release dates are included in this year's paper, along with the additional trends of some neuromorphic, photonic, and memristor-based inference accelerators.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Hardware Architecture},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/E6SP83V9/Reuther et al. - 2022 - AI and ML Accelerator Survey and Trends.pdf}
}

@misc{reutherSurveyBenchmarkingMachine2019,
  title = {Survey and {{Benchmarking}} of {{Machine Learning Accelerators}}},
  author = {Reuther, Albert and Michaleas, Peter and Jones, Michael and Gadepally, Vijay and Samsi, Siddharth and Kepner, Jeremy},
  year = {2019},
  month = aug,
  journal = {arXiv.org},
  doi = {10.1109/HPEC.2019.8916327},
  urldate = {2024-09-10},
  abstract = {Advances in multicore processors and accelerators have opened the flood gates to greater exploration and application of machine learning techniques to a variety of applications. These advances, along with breakdowns of several trends including Moore's Law, have prompted an explosion of processors and accelerators that promise even greater computational and machine learning capabilities. These processors and accelerators are coming in many forms, from CPUs and GPUs to ASICs, FPGAs, and dataflow accelerators. This paper surveys the current state of these processors and accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. We then select and benchmark two commercially-available low size, weight, and power (SWaP) accelerators as these processors are the most interesting for embedded and mobile machine learning inference applications that are most applicable to the DoD and other SWaP constrained users. We determine how they actually perform with real-world images and neural network models, compare those results to the reported performance and power consumption values and evaluate them against an Intel CPU that is used in some embedded applications.},
  howpublished = {https://arxiv.org/abs/1908.11348v1},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/JFJ38BWX/Reuther et al. - 2019 - Survey and Benchmarking of Machine Learning Accelerators.pdf}
}

@article{reutherSurveyMachineLearning,
  title = {Survey of {{Machine Learning Accelerators}}},
  author = {Reuther, Albert and Michaleas, Peter and Jones, Michael and Gadepally, Vijay and Samsi, Siddharth and Kepner, Jeremy},
  abstract = {New machine learning accelerators are being announced and released each month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of of AI accelerators and processors from last year's IEEEHPEC paper. This paper collects and summarizes the current accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. This year, there are many more announced accelerators that are implemented with many more architectures and technologies from vector engines, dataflow engines, neuromorphic designs, flash-based analog memory processing, and photonicbased processing.},
  langid = {english},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/TI2IKV77/Reuther et al. - Survey of Machine Learning Accelerators.pdf}
}

@book{rodriguezDeepLearningSystems2021,
  title = {Deep {{Learning Systems}}: {{Algorithms}}, {{Compilers}}, and {{Processors}} for {{Large-Scale Production}}},
  shorttitle = {Deep {{Learning Systems}}},
  author = {Rodriguez, Andres},
  year = {2021},
  series = {Synthesis {{Lectures}} on {{Computer Architecture}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-01769-8},
  urldate = {2024-10-25},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-031-00641-8 978-3-031-01769-8},
  langid = {english}
}

@article{schererEmotionMulticomponentProcess1984,
  title = {Emotion as a Multicomponent Process: {{A}} Model and Some Cross-Cultural Data},
  shorttitle = {Emotion as a Multicomponent Process},
  author = {Scherer, Klaus R.},
  year = {1984},
  journal = {Review of Personality \& Social Psychology},
  volume = {5},
  pages = {37--63},
  publisher = {Sage Publications, Inc.},
  address = {US},
  issn = {0270-1987},
  abstract = {The author discusses the steps in the development of his component process model (CPM) of emotions. In 1981 he proposed a formal model to extend the original idea about the role of the stimulus evaluation factors in differentiating emotional states to a sequence model. This model states that the differentiated emotional states are the result of the successive outcomes of a series of stimulus evaluation checks. A CPM of emotion was then developed. The CPM postulates 5 functionally defined subsystems of an organism that are centrally involved in the emotional process: information processing, support, executive, action, and monitoring. Differences between this theory and discrete emotion theory are discussed, and the CPM is used to account for the semantic structure of natural language emotion terms. Two studies, involving 10 Ss who sorted emotion terms and 636 students who completed a questionnaire on situations that provoke emotional arousal, are cited, and results concerning antecedents and reactions are noted. (38 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotional Responses,Emotions,Language,Models,Semantics},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/PRC8AB3K/1986-17269-001.html}
}

@inproceedings{seshadriEvaluationEdgeTPU2022,
  title = {An {{Evaluation}} of {{Edge TPU Accelerators}} for {{Convolutional Neural Networks}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{Workload Characterization}} ({{IISWC}})},
  author = {Seshadri, Kiran and Akin, Berkin and Laudon, James and Narayanaswami, Ravi and Yazdanbakhsh, Amir},
  year = {2022},
  month = nov,
  pages = {79--91},
  doi = {10.1109/IISWC55918.2022.00017},
  urldate = {2024-12-09},
  abstract = {Edge TPUs are a domain of accelerators for low-power, edge devices and are widely used in various Google products such as Coral and Pixel devices. In this paper, we first discuss the major microarchitectural details of Edge TPUs. Then, we extensively evaluate three classes of Edge TPUs, covering different computing ecosystems, across 423K unique convolutional neural networks. Building upon this extensive study, we discuss critical and interpretable microarchitectural insights about the studied classes of Edge TPUs. Mainly, we discuss how Edge TPU accelerators perform across convolutional neural networks with different structures. Finally, we present a learned machine learning model with high accuracy to estimate the major performance metrics of accelerators. These learned models enable significantly faster (in the order of milliseconds) evaluations of accelerators as an alternative to time-consuming cycle-accurate simulators and establish an exciting opportunity for rapid hardware/software co-design.},
  keywords = {CNN,Computational modeling,convolutional neural network,Correlation,DNN,Ecosystems,edge devices,Edge TPU,embedded systems,Energy consumption,machine learning,Machine learning,Measurement,Microarchitecture,microprocessor chips,optimization,performance evaluation},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/FXRBC983/9975395.html}
}

@misc{seshadriEvaluationEdgeTPU2022a,
  title = {An {{Evaluation}} of {{Edge TPU Accelerators}} for {{Convolutional Neural Networks}}},
  author = {Seshadri, Kiran and Akin, Berkin and Laudon, James and Narayanaswami, Ravi and Yazdanbakhsh, Amir},
  year = {2022},
  month = oct,
  number = {arXiv:2102.10423},
  eprint = {2102.10423},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2102.10423},
  urldate = {2024-12-09},
  abstract = {Edge TPUs are a domain of accelerators for low-power, edge devices and are widely used in various Google products such as Coral and Pixel devices. In this paper, we first discuss the major microarchitectural details of Edge TPUs. Then, we extensively evaluate three classes of Edge TPUs, covering different computing ecosystems, that are either currently deployed in Google products or are the product pipeline, across 423K unique convolutional neural networks. Building upon this extensive study, we discuss critical and interpretable microarchitectural insights about the studied classes of Edge TPUs. Mainly, we discuss how Edge TPU accelerators perform across convolutional neural networks with different structures. Finally, we present our ongoing efforts in developing high-accuracy learned machine learning models to estimate the major performance metrics of accelerators such as latency and energy consumption. These learned models enable significantly faster (in the order of milliseconds) evaluations of accelerators as an alternative to time-consuming cycle-accurate simulators and establish an exciting opportunity for rapid hard-ware/software co-design.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Hardware Architecture,Computer Science - Machine Learning},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/7QFCE9Z7/Seshadri et al. - 2022 - An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/ANUK8I49/2102.html}
}

@inproceedings{shahidSurveyComparingSpecialized2020,
  title = {A {{Survey Comparing Specialized Hardware And Evolution In TPUs For Neural Networks}}},
  booktitle = {2020 {{IEEE}} 23rd {{International Multitopic Conference}} ({{INMIC}})},
  author = {Shahid, Amna and Mushtaq, Malaika},
  year = {2020},
  month = nov,
  pages = {1--6},
  issn = {2049-3630},
  doi = {10.1109/INMIC50486.2020.9318136},
  urldate = {2024-12-09},
  abstract = {This survey paper is based on the evolution of TPUs from first generation TPUs to edge TPUs and their architectures. This paper compares CPUs, GPUs, FPGAs and TPUs, their hardware architectures, their similarities and differences will be discussed. Modern neural networks are immensely used these days but they require more time, computation and energy. Due to the greater demand and attractive options for architects to explore, companies are continuously working to reduce training and inference response time. Due to the demands and cost factors different kinds of ASICs (application specific integrated circuits) are developed and research is increased in this area. Many models of CPUs, GPUs and TPUs have been developed to support these networks and to improve training and inference phase. Intel developed CPUs for this purpose, NVIDIA developed GPUs and Google developed cloud TPUs. The hardware of CPUs and GPUs can be sold to businesses while Google offers TPU processing for everyone from the cloud. When the data is away from the computational source, it increases the overall cost and to reduce this cost companies implements memory management and caching techniques close to ALUs.},
  keywords = {Deep Learning,GPU,Neural Networks,TPU},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/VLHP727M/Shahid and Mushtaq - 2020 - A Survey Comparing Specialized Hardware And Evolution In TPUs For Neural Networks.pdf}
}

@article{shanliBlendedEmotionIntheWild2019,
  title = {Blended {{Emotion}} In-the-{{Wild}}: {{Multi-label Facial Expression Recognition Using Crowdsourced Annotations}} and {{Deep Locality Feature Learning}}},
  shorttitle = {Blended {{Emotion}} In-the-{{Wild}}},
  author = {{Shan Li} and {Weihong Deng}},
  year = {2019},
  month = jun,
  journal = {International Journal of Computer Vision},
  volume = {127},
  number = {6-7},
  pages = {884--906},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-018-1131-1},
  urldate = {2024-03-30},
  langid = {english}
}

@article{skliarovaSurveyNetworkBasedHardware2022,
  title = {A {{Survey}} of {{Network-Based Hardware Accelerators}}},
  author = {Skliarova, Iouliia},
  year = {2022},
  month = jan,
  journal = {Electronics},
  volume = {11},
  number = {7},
  pages = {1029},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics11071029},
  urldate = {2024-10-26},
  abstract = {Many practical data-processing algorithms fail to execute efficiently on general-purpose CPUs (Central Processing Units) due to the sequential matter of their operations and memory bandwidth limitations. To achieve desired performance levels, reconfigurable (FPGA (Field-Programmable Gate Array)-based) hardware accelerators are frequently explored that permit the processing units' architectures to be better adapted to the specific problem/algorithm requirements. In particular, network-based data-processing algorithms are very well suited to implementation in reconfigurable hardware because several data-independent operations can easily and naturally be executed in parallel over as many processing blocks as actually required and technically possible. GPUs (Graphics Processing Units) have also demonstrated good results in this area but they tend to use significantly more power than FPGA, which could be a limiting factor in embedded applications. Moreover, GPUs employ a Single Instruction, Multiple Threads (SIMT) execution model and are therefore optimized to SIMD (Single Instruction, Multiple Data) operations, while in FPGAs fully custom datapaths can be built, eliminating much of the control overhead. This review paper aims to analyze, compare, and discuss different approaches to implementing network-based hardware accelerators in FPGA and programmable SoC (Systems-on-Chip). The performed analysis and the derived recommendations would be useful to hardware designers of future network-based hardware accelerators.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {counting networks,network-based algorithms,network-based hardware accelerators,reconfigurable hardware,searching networks,sorting networks,survey},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/IAN7EDBZ/Skliarova - 2022 - A Survey of Network-Based Hardware Accelerators.pdf}
}

@article{SparseCoreAcceleratorStructurally,
  title = {{{SparseCore}}: {{An Accelerator}} for {{Structurally Sparse CNNs}}},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/VVIT79SK/SparseCore An Accelerator for Structurally Sparse CNNs.pdf}
}

@article{t.k.moonExpectationmaximizationAlgorithm1996,
  title = {The Expectation-Maximization Algorithm},
  author = {{T.K. Moon}},
  year = {1996},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {13},
  number = {6},
  pages = {47--60},
  issn = {1558-0792},
  doi = {10.1109/79.543975},
  urldate = {2024-03-30},
  abstract = {A common task in signal processing is the estimation of the parameters of a probability distribution function. Perhaps the most frequently encountered estimation problem is the estimation of the mean of a signal in noise. In many parameter estimation problems the situation is more complicated because direct access to the data necessary to estimate the parameters is impossible, or some of the data are missing. Such difficulties arise when an outcome is a result of an accumulation of simpler outcomes, or when outcomes are clumped together, for example, in a binning or histogram operation. There may also be data dropouts or clustering in such a way that the number of underlying data points is unknown (censoring and/or truncation). The EM (expectation-maximization) algorithm is ideally suited to problems of this sort, in that it produces maximum-likelihood (ML) estimates of parameters when there is a many-to-one mapping from an underlying distribution to the distribution governing the observation. The EM algorithm is presented at a level suitable for signal processing practitioners who have had some exposure to estimation theory.},
  keywords = {Convergence,Estimation theory,Hidden Markov models,Histograms,Image reconstruction,Maximum likelihood estimation,Parameter estimation,Phase detection,Probability distribution,Signal processing algorithms},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/4RLW322B/543975.html}
}

@misc{tehCOUDERRobustTopology2020,
  title = {{{COUDER}}: {{Robust Topology Engineering}} for {{Optical Circuit Switched Data Center Networks}}},
  shorttitle = {{{COUDER}}},
  author = {Teh, Min Yee and Zhao, Shizhen and Cao, Peirui and Bergman, Keren},
  year = {2020},
  month = sep,
  number = {arXiv:2010.00090},
  eprint = {2010.00090},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.00090},
  urldate = {2025-01-23},
  abstract = {Many optical circuit switched data center networks (DCN) have been proposed in the past to attain higher capacity and topology reconfigurability, though commercial adoption of these architectures have been minimal. One major challenge these architectures face is the difficulty of handling uncertain traffic demands using commercial optical circuit switches (OCS) with high switching latency. Prior works have generally focused on developing fast-switching OCS prototypes to quickly react to traffic changes through frequent reconfigurations. This approach, however, adds tremendous complexity to the control plane, and raises the barrier for commercial adoption of optical circuit switched data center networks. We propose COUDER, a robust topology and routing optimization framework for reconfigurable optical circuit switched data centers. COUDER optimizes topology and routing based on a convex set of traffic matrices, and offers strict throughput guarantees for any future traffic matrices bounded by the convex set. For the bursty traffic demands that are unbounded by the convex set, we employ a desensitization technique to reduce performance hit. This enables COUDER to generate topology and routing solutions capable of handling unexpected traffic changes without relying on frequent topology reconfigurations. Our extensive evaluations based on Facebook's production DCN traces show that, even with daily reconfiguration, COUDER achieves about 20{\textbackslash}\% higher throughput, and about 32{\textbackslash}\% lower average hop count compared to cost-equivalent static topologies. Our work shows that adoption of reconfigurable topologies in commercial DCNs is feasible even without fast OCSs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Networking and Internet Architecture},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/QBKDBA5X/Teh et al. - 2020 - COUDER Robust Topology Engineering for Optical Circuit Switched Data Center Networks.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/FET2AT3Y/2010.html}
}

@article{TenLessonsThree,
  title = {Ten {{Lessons From Three Generations Shaped}} - {{Norman P}}. {{Jouppi}}},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/UQYEU6K4/Ten Lessons From Three Generations Shaped - Norman P. Jouppi.pdf}
}

@misc{thoppilanLaMDALanguageModels2022,
  title = {{{LaMDA}}: {{Language Models}} for {{Dialog Applications}}},
  shorttitle = {{{LaMDA}}},
  author = {Thoppilan, Romal and Freitas, Daniel De and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and Li, YaGuang and Lee, Hongrae and Zheng, Huaixiu Steven and Ghafouri, Amin and Menegali, Marcelo and Huang, Yanping and Krikun, Maxim and Lepikhin, Dmitry and Qin, James and Chen, Dehao and Xu, Yuanzhong and Chen, Zhifeng and Roberts, Adam and Bosma, Maarten and Zhao, Vincent and Zhou, Yanqi and Chang, Chung-Ching and Krivokon, Igor and Rusch, Will and Pickett, Marc and Srinivasan, Pranesh and Man, Laichee and {Meier-Hellstern}, Kathleen and Morris, Meredith Ringel and Doshi, Tulsee and Santos, Renelito Delos and Duke, Toju and Soraker, Johnny and Zevenbergen, Ben and Prabhakaran, Vinodkumar and Diaz, Mark and Hutchinson, Ben and Olson, Kristen and Molina, Alejandra and {Hoffman-John}, Erin and Lee, Josh and Aroyo, Lora and Rajakumar, Ravi and Butryna, Alena and Lamm, Matthew and Kuzmina, Viktoriya and Fenton, Joe and Cohen, Aaron and Bernstein, Rachel and Kurzweil, Ray and {Aguera-Arcas}, Blaise and Cui, Claire and Croak, Marian and Chi, Ed and Le, Quoc},
  year = {2022},
  month = feb,
  number = {arXiv:2201.08239},
  eprint = {2201.08239},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.08239},
  urldate = {2025-01-23},
  abstract = {We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/I9UQGEBW/Thoppilan et al. - 2022 - LaMDA Language Models for Dialog Applications.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/JEYACU7J/2201.html}
}

@book{tompkinsAffectImageryConsciousness1963,
  title = {Affect, Imagery, Consciousness: {{II}}. {{The Negative Affects}}},
  shorttitle = {Affect, Imagery, Consciousness},
  author = {Tompkins, Silvan S.},
  year = {1963},
  series = {Affect, Imagery, Consciousness: {{II}}. {{The Negative Affects}}},
  pages = {580},
  publisher = {Springer},
  address = {Oxford, England},
  abstract = {Part 2 of a 3 volume general theory of personality. Introduces the "negative affects" distress, contempt and shame. 4 models with a theory of learning are presented to account for the strength of negative affect on personality. Shame is described as the dominant negative affect in a democratic society and contempt in a hierarchically organized society. Distinction between distress-anxiety, and shame, contempt, internalized aggression are made. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Z7ZJDCIL/1965-07714-000.html}
}

@misc{UCSBarchlabOpenTPU2024,
  title = {{{UCSBarchlab}}/{{OpenTPU}}},
  year = {2024},
  month = oct,
  urldate = {2024-10-25},
  abstract = {A open source reimplementation of Google's Tensor Processing Unit (TPU).},
  copyright = {BSD-3-Clause},
  howpublished = {UCSBarchlab}
}

@misc{urataMissionApolloLanding2022,
  title = {Mission {{Apollo}}: {{Landing Optical Circuit Switching}} at {{Datacenter Scale}}},
  shorttitle = {Mission {{Apollo}}},
  author = {Urata, Ryohei and Liu, Hong and Yasumura, Kevin and Mao, Erji and Berger, Jill and Zhou, Xiang and Lam, Cedric and Bannon, Roy and Hutchinson, Darren and Nelson, Daniel and Poutievski, Leon and Singh, Arjun and Ong, Joon and Vahdat, Amin},
  year = {2022},
  month = aug,
  number = {arXiv:2208.10041},
  eprint = {2208.10041},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.10041},
  urldate = {2025-01-23},
  abstract = {In this paper, we describe Apollo, to the best of our knowledge, the world's first large-scale production deployment of optical circuit switches (OCSes) for datacenter networking. We will first describe the infrastructure challenges and use cases that motivated optical switching inside datacenters. We then delve into the requirements of OCSes for datacenter applications: balancing cost, port count, switching time, and optical performance, which drive design choices and implementation details of our internally developed 3D MEMS-based OCS. To enable the Apollo optical switching layer, we employ circulators to realize bidirectional links through the OCS, effectively doubling the OCS radix. The OCS and circulator design choices were critical for meeting network bandwidth, scale, and cost targets. We review the critical co-design of WDM transceiver technology for these OCS plus circulator-based bidirectional links and their corresponding physical impairments, delivered over four generations/speeds of optical interconnect. Finally, we conclude with thoughts on future directions in hardware development and associated applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Networking and Internet Architecture},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/JXVJX4KF/Urata et al. - 2022 - Mission Apollo Landing Optical Circuit Switching at Datacenter Scale.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/343ATX3W/2208.html}
}

@inproceedings{vermaEnclaveSimMicroarchitecturalSimulator2022,
  title = {{{EnclaveSim}}:{{A Micro-architectural Simulator}} with {{Enclave Support}}},
  shorttitle = {{{EnclaveSim}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{Hardware Oriented Security}} and {{Trust}} ({{HOST}})},
  author = {Verma, Yashika and Kumar, Dixit and Panda, Biswabandan},
  year = {2022},
  month = jun,
  pages = {1--4},
  doi = {10.1109/HOST54066.2022.9839725},
  urldate = {2024-10-25},
  abstract = {Intel SGX preserves the confidentiality and integrity aspects of data and code through enclaves (that reside in the trusted part of the memory) and protects it from different layers of the malicious system software, including the OS. Micro-architecture research in the presence of SGX is an interesting theme to explore as SGX does not mitigate timing side-channel attacks at various levels of a memory hierarchy and causes significant performance slowdown. The research community extensively uses existing benchmark suites like SPEC CPU 2017 for evaluating new proposals on the various aspects of micro-architecture research. As there is no benchmark suite available for micro-architecture research with SGX, state-of-the-art micro-architecture research in the presence of SGX assumes an entire SPEC benchmark is running inside an enclave. In reality, Intel SGX assumes that a major portion of the application's code and data do not require security, and only a tiny fraction of it needs security via an enclave. To the best of our knowledge, there are no open-source micro-architectural simulators that can simulate Intel SGX fairly, for micro-architecture research. In this regard, we propose EnclaveSim, a detailed yet flexible, trace-based micro-architectural simulator that simulates trusted code execution through enclaves.},
  keywords = {Benchmark testing,Codes,Hardware,Security,Side-channel attacks,System software,Timing},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/WZSRG6GL/EnclaveSim_A_Micro_architectural_Simulat.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Q6SYBC3H/9839725.html}
}

@inproceedings{wenDiscriminativeFeatureLearning2016,
  title = {A {{Discriminative Feature Learning Approach}} for {{Deep Face Recognition}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2016},
  author = {Wen, Yandong and Zhang, Kaipeng and Li, Zhifeng and Qiao, Yu},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  year = {2016},
  pages = {499--515},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-46478-7_31},
  abstract = {Convolutional neural networks (CNNs) have been widely used in computer vision community, significantly improving the state-of-the-art. In most of the available CNNs, the softmax loss function is used as the supervision signal to train the deep model. In order to enhance the discriminative power of the deeply learned features, this paper proposes a new supervision signal, called center loss, for face recognition task. Specifically, the center loss simultaneously learns a center for deep features of each class and penalizes the distances between the deep features and their corresponding class centers. More importantly, we prove that the proposed center loss function is trainable and easy to optimize in the CNNs. With the joint supervision of softmax loss and center loss, we can train a robust CNNs to obtain the deep features with the two key learning objectives, inter-class dispension and intra-class compactness as much as possible, which are very essential to face recognition. It is encouraging to see that our CNNs (with such joint supervision) achieve the state-of-the-art accuracy on several important face recognition benchmarks, Labeled Faces in the Wild (LFW), YouTube Faces (YTF), and MegaFace Challenge. Especially, our new approach achieves the best results on MegaFace (the largest public domain face benchmark) under the protocol of small training set (contains under 500000 images and under 20000 persons), significantly improving the previous results and setting new state-of-the-art for both face recognition and face verification tasks.},
  isbn = {978-3-319-46478-7},
  langid = {english},
  keywords = {Center loss,Convolutional neural networks,Discriminative feature learning,Face recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/M8VLQAUL/Wen et al. - 2016 - A Discriminative Feature Learning Approach for Dee.pdf}
}

@article{zhengyaowenDistractYourAttention2023,
  title = {Distract {{Your Attention}}: {{Multi-head Cross Attention Network}} for {{Facial Expression Recognition}}},
  shorttitle = {Distract {{Your Attention}}},
  author = {{Zhengyao Wen} and {Wenzhong Lin} and {Tao Wang} and {Ge Xu}},
  year = {2023},
  month = may,
  journal = {Biomimetics},
  volume = {8},
  number = {2},
  eprint = {2109.07270},
  primaryclass = {cs},
  pages = {199},
  issn = {2313-7673},
  doi = {10.3390/biomimetics8020199},
  urldate = {2024-03-30},
  abstract = {We present a novel facial expression recognition network, called Distract your Attention Network (DAN). Our method is based on two key observations. Firstly, multiple classes share inherently similar underlying facial appearance, and their differences could be subtle. Secondly, facial expressions exhibit themselves through multiple facial regions simultaneously, and the recognition requires a holistic approach by encoding high-order interactions among local features. To address these issues, we propose our DAN with three key components: Feature Clustering Network (FCN), Multi-head cross Attention Network (MAN), and Attention Fusion Network (AFN). The FCN extracts robust features by adopting a large-margin learning objective to maximize class separability. In addition, the MAN instantiates a number of attention heads to simultaneously attend to multiple facial areas and build attention maps on these regions. Further, the AFN distracts these attentions to multiple locations before fusing the attention maps to a comprehensive one. Extensive experiments on three public datasets (including AffectNet, RAF-DB, and SFEW 2.0) verified that the proposed method consistently achieves state-of-the-art facial expression recognition performance. Code will be made available at https://github.com/yaoing/DAN.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/QKJ924FZ/Wen et al. - 2023 - Distract Your Attention Multi-head Cross Attentio.pdf;/home/prabinkumarsabat/snap/zotero-snap/common/Zotero/storage/Y2ZHL9BC/2109.html}
}

@misc{zotero-item-148,
  type = {Misc}
}
